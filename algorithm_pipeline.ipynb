{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "796e8f20-cc18-48ae-bc90-11e03901c1dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import import_ipynb\n",
    "from constants import *\n",
    "from simulation import simul\n",
    "from utils import *\n",
    "\n",
    "from algorithms.centrality import outdegree, betweenness, pagerank\n",
    "from algorithms.greedy import greedy_orig\n",
    "from algorithms.BPM import BPM, greedy_BPM\n",
    "from algorithms.KED import KED\n",
    "from algorithms.MDS import MDS\n",
    "from algorithms.RIS import RIS\n",
    "from algorithms.random import random_edge\n",
    "from algorithms.DiffIM import DiffIM, DiffIMp, DiffIMpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b5a9d7-797e-4949-94d4-385dce986875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mask(save_dir, file_num, mask, seed_size, infl_orig, infl_masked, time_alg):\n",
    "    with open(save_dir+f'/mask_{file_num}.txt','w') as f:\n",
    "        f.write('seed infl_orig infl_masked reduced\\n')\n",
    "        f.write(f'{seed_size} {infl_orig} {infl_masked} {(infl_orig-infl_masked)/(infl_orig-seed_size)}\\n')\n",
    "        f.write('u v p time%\\n')\n",
    "        for i in range(len(mask)):\n",
    "            u,v,p = mask[i]\n",
    "            t = time_alg[i]\n",
    "            f.write(f'{int(u)} {int(v)} {p} {t}\\n')\n",
    "\n",
    "\n",
    "def save_record(save_dir, record, time_pretrain):\n",
    "    # record : [k,(seed_size,infl_orig,infl_masked,time)]\n",
    "    reduceds = (record[:,1]-record[:,2])/(record[:,1]-record[:,0])\n",
    "    times = record[:,3]\n",
    "    with open(save_dir+'/summary.txt','w') as f:\n",
    "        f.write(f'reduced_avg: {np.mean(reduceds)}, reduced_std: {np.std(reduceds)}, time_avg: {np.mean(times)}, time_std: {np.std(times)}\\n')\n",
    "        f.write(f'pretrain time: {time_pretrain}\\n')\n",
    "        f.write('seed infl_orig infl_masked reduced time\\n')\n",
    "        for seed_size, infl_orig, infl_masked, time_alg in record: f.write(f'{seed_size} {infl_orig} {infl_masked} {(infl_orig-infl_masked)/(infl_orig-seed_size)} {time_alg}\\n')\n",
    "\n",
    "\n",
    "def pipeline(alg_name, dataset_name, del_edge_num, save=True, save_tag=None, data_num=None, adv_log_save=False, verbose=False, **alg_kwags):\n",
    "    # prepare saving dir\n",
    "    if save:\n",
    "        dataset_tag = ABBR.get(dataset_name, dataset_name[:-7])\n",
    "        save_dir = RESULT_DIR+dataset_tag+'/'+str(del_edge_num)+'/'+alg_name\n",
    "        if save_tag : save_dir += save_tag\n",
    "        if not os.path.exists(save_dir): os.makedirs(save_dir)\n",
    "\n",
    "        if adv_log_save:\n",
    "            adv_log_dir = save_dir+'/adv_log/'\n",
    "            if not os.path.exists(adv_log_dir): os.makedirs(adv_log_dir)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # algorithm list\n",
    "    basic_ind2seed = {'BPM':BPM, 'KED':KED, 'random':random_edge, 'outdegree':outdegree, 'betweenness':betweenness, 'pagerank':pagerank}  # seed-independent\n",
    "    basic_algs = {'MDS':MDS, 'greedy':greedy_orig, 'MBPM':greedy_BPM, 'RIS':RIS}\n",
    "    pyg_algs = {'DiffIM':DiffIM, 'DiffIM+':DiffIMp, 'DiffIM++':DiffIMpp}\n",
    "    \n",
    "    # load algorithm\n",
    "    is_once = False\n",
    "    is_pyg = False\n",
    "    time_pretrain = 0\n",
    "    if alg_name in basic_algs:\n",
    "        algorithm = basic_algs[alg_name]\n",
    "    elif alg_name in basic_ind2seed:\n",
    "        is_once = True\n",
    "        algorithm = basic_ind2seed[alg_name]\n",
    "    elif alg_name in pyg_algs:\n",
    "        is_pyg = True\n",
    "        algorithm = pyg_algs[alg_name]\n",
    "    else: raise Exception(\"not supported algorithm name\")\n",
    "    \n",
    "    # load dataset\n",
    "    graph_name = dataset_name.split('-')[0]\n",
    "    n,m,adj_list = txt2adj(graph_name)\n",
    "    with gzip.open(DATASET_DIR+dataset_name, 'rb') as f: rawdata = pickle.load(f)\n",
    "    if data_num==None: data_num = len(rawdata)\n",
    "    if del_edge_num=='all': del_edge_num = m\n",
    "\n",
    "    if is_once:  # seed-independent algs run only once\n",
    "        is_seed, probs = rawdata[0]\n",
    "        seed_idx = np.where(is_seed==1)[0]\n",
    "        \n",
    "        mask, time_alg = algorithm(adj_list, seed_idx, del_edge_num, **alg_kwags)\n",
    "            \n",
    "        if not isinstance(time_alg,list) : time_alg = [time_alg]*del_edge_num\n",
    "        elif len(time_alg)==1: time_alg = time_alg*del_edge_num\n",
    "\n",
    "        adj_mat_masked = list2mat(adj_list)\n",
    "        for u,v,p in mask: adj_mat_masked[int(u)][int(v)]=0\n",
    "        adj_list_masked = mat2list(adj_mat_masked)\n",
    "\n",
    "    record = []\n",
    "    if verbose: print('seed\\tinfl_orig\\tinfl_mask\\treldec%\\t\\ttime')\n",
    "    for file_num, (is_seed, probs) in enumerate(rawdata[:data_num]):  \n",
    "        seed_idx = np.where(is_seed==1)[0]\n",
    "\n",
    "        adv_log_filename = adv_log_dir+f'{file_num}.txt' if adv_log_save else None\n",
    "\n",
    "        if not is_once:\n",
    "            # call algorithm\n",
    "            if is_pyg: mask, time_alg = algorithm(adj_list, seed_idx, probs, del_edge_num, log_filename=adv_log_filename, **alg_kwags)\n",
    "            else: mask, time_alg = algorithm(adj_list, seed_idx, del_edge_num, **alg_kwags)\n",
    "    \n",
    "            # adjust time_alg\n",
    "            if not isinstance(time_alg,list) : time_alg = [time_alg]*del_edge_num\n",
    "            elif len(time_alg)==1: time_alg = time_alg*del_edge_num\n",
    "    \n",
    "            # apply mask to adj_list. (convert to adj_mat -> apply mask -> convert to adj_list)\n",
    "            adj_mat_masked = list2mat(adj_list)\n",
    "            for u,v,p in mask: adj_mat_masked[int(u)][int(v)]=0\n",
    "            adj_list_masked = mat2list(adj_mat_masked)\n",
    "\n",
    "        # influence before/after apply mask\n",
    "        infl_orig = sum(probs)\n",
    "        infl_masked = sum(simul(adj_list_masked,seed_idx))\n",
    "        if verbose: print(f'{len(seed_idx)}\\t{infl_orig :.2f}\\t\\t{infl_masked :.2f}\\t\\t{(infl_orig-infl_masked)/(infl_orig-len(seed_idx)) :.4f}\\t\\t{time_alg[-1]:.4f}')\n",
    "        record.append([len(seed_idx),infl_orig,infl_masked,time_alg[-1]])\n",
    "\n",
    "        # save mask\n",
    "        if save: save_mask(save_dir, file_num, mask, len(seed_idx), infl_orig, infl_masked, time_alg)\n",
    "\n",
    "    record = np.array(record)\n",
    "    avgtime = np.mean(record[:,3])\n",
    "    avgreldec = np.mean((record[:,1]-record[:,2])/(record[:,1]-record[:,0]))\n",
    "    if verbose: print(f'avgreldec%: {avgreldec:.4f}, avgtime: {avgtime:.4f}')\n",
    "    \n",
    "    # save record\n",
    "    if save: save_record(save_dir, record, time_pretrain)\n",
    "    return avgreldec, record, time_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a9d34b-9969-4bda-bacd-e7fe21596a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for greedy-like algorithm, if already have budget k results, then we can generate budget<k reulsts quickly\n",
    "def make_subresult(alg_name, dataset_name, from_del_edge_num, to_del_edge_num, save_tag=None):\n",
    "    # prepare saving dir\n",
    "    dataset_tag = ABBR.get(dataset_name, dataset_name[:-7])\n",
    "    from_save_dir = RESULT_DIR+dataset_tag+'/'+str(from_del_edge_num)+'/'+alg_name\n",
    "    to_save_dir = RESULT_DIR+dataset_tag+'/'+str(to_del_edge_num)+'/'+alg_name\n",
    "    if save_tag : from_save_dir += save_tag; to_save_dir += save_tag\n",
    "    if not os.path.exists(from_save_dir): print('no such directory'); return\n",
    "    if not os.path.exists(to_save_dir): os.makedirs(to_save_dir)\n",
    "    \n",
    "    # load dataset\n",
    "    graph_name = dataset_name.split('-')[0]\n",
    "    n,m,adj_list = txt2adj(graph_name)\n",
    "    with gzip.open(DATASET_DIR+dataset_name, 'rb') as f: rawdata = pickle.load(f)\n",
    "\n",
    "    record = []\n",
    "    for file_num, (is_seed, probs) in enumerate(rawdata): \n",
    "        mask = []\n",
    "        time_alg = []\n",
    "        with open(from_save_dir+f'/mask_{file_num}.txt','r') as f:\n",
    "            f.readline()\n",
    "            seed_size, infl_orig, _, _ = map(float,f.readline().split())\n",
    "            f.readline()\n",
    "            for i in range(to_del_edge_num):\n",
    "                u,v,p,t = map(float,f.readline().split())\n",
    "                mask.append((int(u),int(v),p))\n",
    "                time_alg.append(t)\n",
    "        seed_idx = np.where(is_seed==1)[0]\n",
    "\n",
    "        # apply mask to adj_list. (convert to adj_mat -> apply mask -> convert to adj_list)\n",
    "        adj_mat_masked = list2mat(adj_list)\n",
    "        for u,v,p in mask: adj_mat_masked[u][v]=0\n",
    "        adj_list_masked = mat2list(adj_mat_masked)\n",
    "\n",
    "        # influence after apply mask\n",
    "        infl_masked = sum(simul(adj_list_masked,seed_idx))\n",
    "        record.append([len(seed_idx),infl_orig,infl_masked,time_alg[-1]])\n",
    "\n",
    "        # save mask\n",
    "        save_mask(to_save_dir, file_num, mask, len(seed_idx), infl_orig, infl_masked, time_alg)\n",
    "\n",
    "    record = np.array(record)\n",
    "    avgtime = np.mean(record[:,3])\n",
    "    avgreldec = np.mean((record[:,1]-record[:,2])/(record[:,1]-record[:,0]))\n",
    "\n",
    "    with open(from_save_dir+'/summary.txt','r') as f:\n",
    "        f.readline()\n",
    "        time_pretrain = float(f.readline().split()[-1])\n",
    "    \n",
    "    # save record\n",
    "    save_record(to_save_dir, record, time_pretrain)\n",
    "    return avgreldec, record, time_pretrain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
