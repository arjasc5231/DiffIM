{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb29c39-f3f7-441e-87bc-0b5b3e3687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "from torch_geometric.explain import Explainer\n",
    "\n",
    "import import_ipynb\n",
    "from utils import set_gpu, load_model, adj2Data, testDatasetName2pretrainDatasetName\n",
    "from dataset import get_dataloader, get_dataloader2, get_data, get_data_split, get_data_split2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47006363-69ff-43bb-b5e6-36f4268c8ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import logging\n",
    "from typing import Optional, Union\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import ReLU, Sequential\n",
    "\n",
    "from torch_geometric.explain import Explanation\n",
    "from torch_geometric.explain.algorithm import ExplainerAlgorithm\n",
    "from torch_geometric.explain.algorithm.utils import clear_masks, set_masks\n",
    "from torch_geometric.explain.config import (\n",
    "    ExplanationType,\n",
    "    ModelMode,\n",
    "    ModelTaskLevel,\n",
    ")\n",
    "from torch_geometric.nn import Linear\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.utils import get_embeddings\n",
    "\n",
    "\n",
    "class PGExplainer(ExplainerAlgorithm):\n",
    "    r\"\"\"The PGExplainer model from the `\"Parameterized Explainer for Graph\n",
    "    Neural Network\" <https://arxiv.org/abs/2011.04573>`_ paper.\n",
    "    Internally, it utilizes a neural network to identify subgraph structures\n",
    "    that play a crucial role in the predictions made by a GNN.\n",
    "    Importantly, the :class:`PGExplainer` needs to be trained via\n",
    "    :meth:`~PGExplainer.train` before being able to generate explanations:\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        explainer = Explainer(\n",
    "            model=model,\n",
    "            algorithm=PGExplainer(epochs=30, lr=0.003),\n",
    "            explanation_type='phenomenon',\n",
    "            edge_mask_type='object',\n",
    "            model_config=ModelConfig(...),\n",
    "        )\n",
    "\n",
    "        \n",
    "        for epoch in range(30):\n",
    "            for index in [...]:  \n",
    "                loss = explainer.algorithm.train(epoch, model, x, edge_index,\n",
    "                                                 target=target, index=index)\n",
    "\n",
    "        \n",
    "        explanation = explainer(x, edge_index, target=target, index=0)\n",
    "\n",
    "    Args:\n",
    "        epochs (int): The number of epochs to train.\n",
    "        lr (float, optional): The learning rate to apply.\n",
    "            (default: :obj:`0.003`).\n",
    "        **kwargs (optional): Additional hyper-parameters to override default\n",
    "            settings in\n",
    "            :attr:`~torch_geometric.explain.algorithm.PGExplainer.coeffs`.\n",
    "    \"\"\"\n",
    "\n",
    "    coeffs = {\n",
    "        'edge_size': 0.05,\n",
    "        'edge_ent': 1.0,\n",
    "        'temp': [5.0, 2.0],\n",
    "        'bias': 0.0,\n",
    "    }\n",
    "\n",
    "    def __init__(self, epochs: int, lr: float = 0.003,  device='cpu', **kwargs):\n",
    "        super().__init__()\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.coeffs.update(kwargs)\n",
    "        self.device = device\n",
    "\n",
    "        self.mlp = Sequential(\n",
    "            Linear(-1, 64),\n",
    "            ReLU(),\n",
    "            Linear(64, 1),\n",
    "        )\n",
    "        self.mlp.to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.mlp.parameters(), lr=lr)\n",
    "        self._curr_epoch = -1\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        reset(self.mlp)\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        epoch: int,\n",
    "        model: torch.nn.Module,\n",
    "        x: Tensor,\n",
    "        edge_index: Tensor,\n",
    "        *,\n",
    "        target: Tensor,\n",
    "        index: Optional[Union[int, Tensor]] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        r\"\"\"Trains the underlying explainer model.\n",
    "        Needs to be called before being able to make predictions.\n",
    "\n",
    "        Args:\n",
    "            epoch (int): The current epoch of the training phase.\n",
    "            model (torch.nn.Module): The model to explain.\n",
    "            x (torch.Tensor): The input node features of a\n",
    "                homogeneous graph.\n",
    "            edge_index (torch.Tensor): The input edge indices of a homogeneous\n",
    "                graph.\n",
    "            target (torch.Tensor): The target of the model.\n",
    "            index (int or torch.Tensor, optional): The index of the model\n",
    "                output to explain. Needs to be a single index.\n",
    "                (default: :obj:`None`)\n",
    "            **kwargs (optional): Additional keyword arguments passed to\n",
    "                :obj:`model`.\n",
    "        \"\"\"\n",
    "        if isinstance(x, dict) or isinstance(edge_index, dict):\n",
    "            raise ValueError(f\"Heterogeneous graphs not yet supported in \"\n",
    "                             f\"'{self.__class__.__name__}'\")\n",
    "\n",
    "        if self.model_config.task_level == ModelTaskLevel.node:\n",
    "            if index is None:\n",
    "                raise ValueError(f\"The 'index' argument needs to be provided \"\n",
    "                                 f\"in '{self.__class__.__name__}' for \"\n",
    "                                 f\"node-level explanations\")\n",
    "            if isinstance(index, Tensor) and index.numel() > 1:\n",
    "                raise ValueError(f\"Only scalars are supported for the 'index' \"\n",
    "                                 f\"argument in '{self.__class__.__name__}'\")\n",
    "\n",
    "        z = get_embeddings(model, x, edge_index, **kwargs)[-1]\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        temperature = self._get_temperature(epoch)\n",
    "\n",
    "        inputs = self._get_inputs(z, edge_index, index)\n",
    "        logits = self.mlp(inputs).view(-1)\n",
    "        edge_mask = self._concrete_sample(logits, temperature)\n",
    "        set_masks(model, edge_mask, edge_index, apply_sigmoid=True)\n",
    "\n",
    "        if self.model_config.task_level == ModelTaskLevel.node:\n",
    "            _, hard_edge_mask = self._get_hard_masks(model, index, edge_index,\n",
    "                                                     num_nodes=x.size(0))\n",
    "            edge_mask = edge_mask[hard_edge_mask]\n",
    "\n",
    "        y_hat, y = model(x, edge_index, **kwargs), target\n",
    "\n",
    "        if index is not None:\n",
    "            y_hat, y = y_hat[index], y[index]\n",
    "\n",
    "        loss = self._loss(y_hat, y, edge_mask)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        clear_masks(model)\n",
    "        self._curr_epoch = epoch\n",
    "\n",
    "        return float(loss)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        x: Tensor,\n",
    "        edge_index: Tensor,\n",
    "        *,\n",
    "        target: Tensor,\n",
    "        index: Optional[Union[int, Tensor]] = None,\n",
    "        **kwargs,\n",
    "    ) -> Explanation:\n",
    "        if isinstance(x, dict) or isinstance(edge_index, dict):\n",
    "            raise ValueError(f\"Heterogeneous graphs not yet supported in \"\n",
    "                             f\"'{self.__class__.__name__}'\")\n",
    "\n",
    "        if self._curr_epoch < self.epochs - 1:  \n",
    "            raise ValueError(f\"'{self.__class__.__name__}' is not yet fully \"\n",
    "                             f\"trained (got {self._curr_epoch + 1} epochs \"\n",
    "                             f\"from {self.epochs} epochs). Please first train \"\n",
    "                             f\"the underlying explainer model by running \"\n",
    "                             f\"`explainer.algorithm.train(...)`.\")\n",
    "\n",
    "        hard_edge_mask = None\n",
    "        if self.model_config.task_level == ModelTaskLevel.node:\n",
    "            if index is None:\n",
    "                raise ValueError(f\"The 'index' argument needs to be provided \"\n",
    "                                 f\"in '{self.__class__.__name__}' for \"\n",
    "                                 f\"node-level explanations\")\n",
    "            if isinstance(index, Tensor) and index.numel() > 1:\n",
    "                raise ValueError(f\"Only scalars are supported for the 'index' \"\n",
    "                                 f\"argument in '{self.__class__.__name__}'\")\n",
    "\n",
    "            \n",
    "            \n",
    "            _, hard_edge_mask = self._get_hard_masks(model, index, edge_index,\n",
    "                                                     num_nodes=x.size(0))\n",
    "\n",
    "        z = get_embeddings(model, x, edge_index, **kwargs)[-1]\n",
    "\n",
    "        inputs = self._get_inputs(z, edge_index, index)\n",
    "        logits = self.mlp(inputs).view(-1)\n",
    "\n",
    "        edge_mask = self._post_process_mask(logits, hard_edge_mask,\n",
    "                                            apply_sigmoid=True)\n",
    "\n",
    "        return Explanation(edge_mask=edge_mask)\n",
    "\n",
    "    def supports(self) -> bool:\n",
    "        explanation_type = self.explainer_config.explanation_type\n",
    "        if explanation_type != ExplanationType.phenomenon:\n",
    "            logging.error(f\"'{self.__class__.__name__}' only supports \"\n",
    "                          f\"phenomenon explanations \"\n",
    "                          f\"got (`explanation_type={explanation_type.value}`)\")\n",
    "            return False\n",
    "\n",
    "        task_level = self.model_config.task_level\n",
    "        if task_level not in {ModelTaskLevel.node, ModelTaskLevel.graph}:\n",
    "            logging.error(f\"'{self.__class__.__name__}' only supports \"\n",
    "                          f\"node-level or graph-level explanations \"\n",
    "                          f\"got (`task_level={task_level.value}`)\")\n",
    "            return False\n",
    "\n",
    "        node_mask_type = self.explainer_config.node_mask_type\n",
    "        if node_mask_type is not None:\n",
    "            logging.error(f\"'{self.__class__.__name__}' does not support \"\n",
    "                          f\"explaining input node features \"\n",
    "                          f\"got (`node_mask_type={node_mask_type.value}`)\")\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    \n",
    "\n",
    "    def _get_inputs(self, embedding: Tensor, edge_index: Tensor,\n",
    "                    index: Optional[int] = None) -> Tensor:\n",
    "        zs = [embedding[edge_index[0]], embedding[edge_index[1]]]\n",
    "        if self.model_config.task_level == ModelTaskLevel.node:\n",
    "            assert index is not None\n",
    "            zs.append(embedding[index].view(1, -1).repeat(zs[0].size(0), 1))\n",
    "        return torch.cat(zs, dim=-1)\n",
    "\n",
    "    def _get_temperature(self, epoch: int) -> float:\n",
    "        temp = self.coeffs['temp']\n",
    "        return temp[0] * pow(temp[1] / temp[0], epoch / self.epochs)\n",
    "\n",
    "    def _concrete_sample(self, logits: Tensor,\n",
    "                         temperature: float = 1.0) -> Tensor:\n",
    "        bias = self.coeffs['bias']\n",
    "        eps = (1 - 2 * bias) * torch.rand_like(logits) + bias\n",
    "        return (eps.log() - (1 - eps).log() + logits) / temperature\n",
    "\n",
    "    def _loss(self, y_hat: Tensor, y: Tensor, edge_mask: Tensor) -> Tensor:\n",
    "        if self.model_config.mode == ModelMode.binary_classification:\n",
    "            loss = self._loss_binary_classification(y_hat, y)\n",
    "        elif self.model_config.mode == ModelMode.multiclass_classification:\n",
    "            loss = self._loss_multiclass_classification(y_hat, y)\n",
    "        elif self.model_config.mode == ModelMode.regression:\n",
    "            loss = self._loss_regression(y_hat, y)\n",
    "\n",
    "        \n",
    "        mask = edge_mask.sigmoid()\n",
    "        size_loss = mask.sum() * self.coeffs['edge_size']\n",
    "        mask = 0.99 * mask + 0.005\n",
    "        mask_ent = -mask * mask.log() - (1 - mask) * (1 - mask).log()\n",
    "        mask_ent_loss = mask_ent.mean() * self.coeffs['edge_ent']\n",
    "\n",
    "        return loss + size_loss + mask_ent_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8542012-bad7-464c-8879-558ab6e8504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_pyg_pgexplainer(dataset_name, model_name, gpu_num, epochs, lr, print_epoch=1):\n",
    "    device = set_gpu(gpu_num)\n",
    "    model = load_model(model_name, device)\n",
    "    \n",
    "    \n",
    "    if isinstance(dataset_name, str): pretrain_data = get_data(testDatasetName2pretrainDatasetName(dataset_name))\n",
    "    elif isinstance(dataset_name, list):\n",
    "        if len(dataset_name)==2: pretrain_data = get_data2(testDatasetName2pretrainDatasetName(dataset_name[0]), testDatasetName2pretrainDatasetName(dataset_name[1]))  \n",
    "    data_num = len(pretrain_data)\n",
    "    pretrain_dataloader = DataLoader(pretrain_data, batch_size=1, shuffle=True)\n",
    "    \n",
    "    \n",
    "    explainer = Explainer(\n",
    "        model=model,\n",
    "        algorithm=PGExplainer(epochs=epochs, lr=lr, device=device),\n",
    "        explanation_type='phenomenon',\n",
    "        edge_mask_type='object',\n",
    "        model_config=dict(\n",
    "            mode='regression',\n",
    "            task_level='graph',\n",
    "            return_type='raw',\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "    stime = time.time()\n",
    "    for epoch in range(1,epochs+1):\n",
    "        avgloss = 0\n",
    "        for batch in pretrain_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            loss = explainer.algorithm.train(epoch, model, batch.x, batch.edge_index, edge_attr=batch.edge_attr, target=torch.unsqueeze(torch.sum(batch.y,dim=0),0))\n",
    "            avgloss += loss\n",
    "        avgloss /= data_num\n",
    "        if print_epoch and epoch%print_epoch==0: print(f'{epoch} {avgloss:.4f}')\n",
    "    time_pretrain = time.time()-stime\n",
    "\n",
    "    return explainer, time_pretrain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
